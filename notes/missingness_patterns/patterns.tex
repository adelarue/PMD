%!TEX root = patterns.tex

\documentclass{article}

\usepackage{amsmath,amssymb}

\begin{document}
We have some random variables $X, Y$ with joint probability density $p(x,y)$. $X$ is $m$-dimensional (features) and $Y$ is 1-dimensional (target). $Z$ is an $m$-dimensional discrete random variable that indicates the presence of each $X$ (binary). The conditional density function of $Z$ given $X$ and $Y$ is given by $p(z|x,y)$, and the joint distribution of $X$, $Y$ and $Z$ is $p(x, y, z)$.

In the fully adaptive setting, our goal is to find regression weights $w(Z=z)$ for each possible value of $z$ (possible because the set is finite, but unrealistic because it is very large).

Our goal is to solve the following optimization problem, where $\cdot$ represents element-wise multiplication:
\[
\min_{w(z)} \mathbb{E}\left[(w(Z)^T(X\cdot Z)-Y)^2\right]=\min_{w(z)}\int dx\,dy\,dz\,p(x,y,z) (w(z)^T(x\cdot z)-y)^2.
\]

We can break up the joint density $p(x, y, z)=p(z) p(x, y | z)$ and obtain
\begin{align*}
\min_{w(z)} \mathbb{E}\left[(w(Z)^T(X\cdot Z)-Y)^2\right]&=\min_{w(z)} \int dz\,p(z)\int dx\,dy\,p(x,y|z) (w(z)^T(x\cdot z)-y)^2\\
&=\min_{w(z)}\mathbb{E}\left[\mathbb{E}\left[(w(Z)^T(X\cdot Z)-Y)^2|Z\right]\right].
\end{align*}

There is a bit of an abuse of notation because $z$ is discrete (so the integral is actually a finite sum).

Because we have a fully adaptive model, there is a $w(z)$ for each possible value of $z$. So the optimization problem above is separable, and we just want to solve the following problem for each $z$:
\begin{align*}
\min_w \mathbb{E}\left[(w^T(X\cdot Z)-Y)^2|Z=z\right]&=\min_w\int dx\,dy\,p(x, y|z) (w^T(x\cdot z)-y)^2\\
&=\min_w \int dx\,dy\, p(x, y) (w^T(x\cdot z)-y)^2 \frac{p(Z=z|x,y)}{p(Z=z)}.
\end{align*}

\begin{enumerate}

\item If the data is missing completely at random (MCAR), $p(Z=z|x,y)=p(Z=z)$. Then the problem reduces to:
\[
\min_w \mathbb{E}\left[(w^T(X\cdot Z)-Y)^2|Z=z\right] = \min_w \mathbb{E}\left[(w^T(X\cdot z)-Y)^2\right].
\]
In a real setting, where only data is available, we approximate the distribution of $X, Y$ with the empirical distribution. This means we consider all data points in the dataset with at least the features indicated by $Z$ present. This seems equivalent to ``available-case analysis.''

\item If the data is missing at random (MAR), $p(Z=z|x,y)\neq p(Z=z)$. However, if we assume that the conditional distribution $p(z|x,y)$ is known, then we can use data points with a different missingness pattern as long as we reweight their importance appropriately in the expectation. Although in practice, we do not know this probability distribution, so it may be safer to only use data points where $Z$ is realized to be $z$.

\item If the data is not missing at random (NMAR), then not only is $p(Z=z|x,y)\neq p(Z=z)$, but given a data point $x, z, y$, we cannot even calculate the probability of another missingness pattern. So the only safe thing to do is to use only the data points with matching $z$.

\end{enumerate}

Note: under this probabilistic model, there is a big difference between MCAR and MAR/NMAR.

\end{document}