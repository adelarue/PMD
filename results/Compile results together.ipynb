{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method_category (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function method_category(meth)\n",
    "    if startswith(meth, \"Imp-then-Reg\")\n",
    "        return \"Imp-then-Reg\"\n",
    "    elseif startswith(meth, \"Joint Imp-then-Reg\")\n",
    "        return \"Joint Imp-then-Reg\"\n",
    "    elseif meth ∈ [\"Static\", \"Affine\", \"Finite\"]\n",
    "        return \"Adaptive LR\"\n",
    "    elseif startswith(meth, \"Complete Features\")\n",
    "        return \"Complete Features\"\n",
    "    else \n",
    "        return meth\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{String}:\n",
       " \"cylinder-bands\"\n",
       " \"ozone-level-detection-eight\"\n",
       " \"ozone-level-detection-one\"\n",
       " \"thyroid-disease-thyroid-0387\"\n",
       " \"trains\"\n",
       " \"credit-approval\"\n",
       " \"Ecdat-Mofa\"\n",
       " \"sleep\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb_datasets = [\"cylinder-bands\", \"ozone-level-detection-eight\", \"ozone-level-detection-one\", \"thyroid-disease-thyroid-0387\", \"trains\",\n",
    "                \"credit-approval\", \"Ecdat-Mofa\", \"sleep\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Real X - Syn Y Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = \"fakey/\"\n",
    "for y_model in [\"linear\", \"nn\"]\n",
    "    for m_model = [\"mar\", \"nmar\", \"mar_adv\"]\n",
    "        dir = y_model*\"_\"*m_model*\"/\"\n",
    "        directory = setting*dir\n",
    "        \n",
    "        filelist = [f for f in readdir(directory*\"final/\") if endswith(f, \".csv\")]\n",
    "        res = similar(CSV.read(directory*\"final/\"*filelist[1], DataFrame),0)\n",
    "        \n",
    "        for subdir = [\"final/\", \"rf_mia/\"]\n",
    "            filelist = [f for f in readdir(directory*subdir) if endswith(f, \".csv\")]\n",
    "#             res = similar(CSV.read(directory*subdir*filelist[1], DataFrame),0)\n",
    "            for i in 1:length(filelist)\n",
    "                res = vcat(res, CSV.read(directory*subdir*filelist[i], DataFrame))\n",
    "            end\n",
    "        end\n",
    "        res[!,:method_cat] = map(t -> method_category(t), res[:,:method])\n",
    "        res[!,:X_setting] .= \"real_X_\"*m_model\n",
    "        res[!,:Y_setting] .= \"syn_Y_\"*y_model\n",
    "\n",
    "        CSV.write(directory*\"FINAL_results.csv\", res)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = \"fakey/\"\n",
    "\n",
    "for y_model in [\"linear\", \"tree\", \"nn\"]\n",
    "    for m_model = [\"mar\", \"nmar\", \"mar_adv\"]\n",
    "        dir = y_model*\"_\"*m_model*\"/\"\n",
    "        directory = setting*dir\n",
    "  \n",
    "        res = CSV.read(directory*\"FINAL_results.csv\", DataFrame)\n",
    "        \n",
    "        res[!,:method] .= map(t -> (t == \"Affine\" ? \"Adaptive LR - Affine\" : t), res[:,:method]) \n",
    "        res[!,:method] .= map(t -> (t == \"Finite\" ? \"Adaptive LR - Finite\" : t), res[:,:method]) \n",
    "        res[!,:method] .= map(t -> (t == \"Static\" ? \"Adaptive LR - Affine intercept only\" : t), res[:,:method])\n",
    "        \n",
    "        filter!(t -> t[:dataset] ∉ pb_datasets, res)\n",
    "\n",
    "        for method in [\"Oracle X\", \"Oracle XM\", \"Complete Features\", \"Imp-then-Reg 1\", \"Imp-then-Reg 2\", \"Imp-then-Reg 3\", \"Imp-then-Reg 4\", \"Imp-then-Reg 5\", \"Joint Imp-then-Reg\", \"Adaptive LR\"]\n",
    "            aux = filter(t -> startswith(t[:method], method), res)\n",
    "\n",
    "            idcols = [:dataset, :X_setting, :Y_setting, :SNR, :k, :kMissing, :splitnum]\n",
    "            gd = groupby(aux, idcols)\n",
    "\n",
    "            aux = similar(aux, 0)\n",
    "            for subdf in gd \n",
    "                scoremax = argmax(subdf[:,:score])\n",
    "                push!(aux, subdf[scoremax,names(aux)])\n",
    "            end\n",
    "            aux[!,:method] .= method*\" - best\"\n",
    "\n",
    "            res = vcat(res, aux)\n",
    "        end\n",
    "        \n",
    "        CSV.write(directory*\"FINAL_results.csv\", res)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Real Data Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory = [\"realy/\"]\n",
    "    filelist = [f for f in readdir(directory*\"2022-08-23/\") if endswith(f, \".csv\") && f ∉ [\"all_results.csv\",\"all_results_new.csv\"]]\n",
    "    res = similar(CSV.read(directory*\"2022-08-23/\"*filelist[1], DataFrame),0)\n",
    "    \n",
    "    for subdir = [\"2022-08-23/\", \"rf_mia/\"]\n",
    "        filelist = [f for f in readdir(directory*subdir) if endswith(f, \".csv\") && f ∉ [\"all_results.csv\",\"all_results_new.csv\"]]\n",
    "#         res = similar(CSV.read(directory*subdir*filelist[1], DataFrame),0)\n",
    "        for i in 1:length(filelist)\n",
    "            res = vcat(res, CSV.read(directory*subdir*filelist[i], DataFrame))\n",
    "        end\n",
    "    end\n",
    "    # filter!(t -> t[:k] > 0, res) #Remove dataset with only a bias term\n",
    "    res[!,:method_cat] = map(method_category, res[:,:method])\n",
    "    res[!,:X_setting] .= \"real_X\"\n",
    "    res[!,:Y_setting] .= \"real_Y\"\n",
    "    \n",
    "    CSV.write(directory*\"FINAL_results.csv\", res)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = CSV.read(\"realy/\"*\"FINAL_results.csv\", DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique(filter( t-> t[:nrow] < 10, combine(groupby(res, [:dataset, :method]), nrow))[:,[:dataset, :nrow]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `best` variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"realy/FINAL_results.csv\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = CSV.read(\"realy/\"*\"FINAL_results.csv\", DataFrame)\n",
    "\n",
    "filter!(t -> t[:dataset] ∉ pb_datasets, res)\n",
    "\n",
    "res[!,:method] .= map(t -> (t == \"Affine\" ? \"Adaptive LR - Affine\" : t), res[:,:method]) \n",
    "res[!,:method] .= map(t -> (t == \"Finite\" ? \"Adaptive LR - Finite\" : t), res[:,:method]) \n",
    "res[!,:method] .= map(t -> (t == \"Static\" ? \"Adaptive LR - Affine intercept only\" : t), res[:,:method])\n",
    "\n",
    "for method in [\"Complete Features\", \"Imp-then-Reg 1\", \"Imp-then-Reg 2\", \"Imp-then-Reg 3\", \"Imp-then-Reg 4\", \"Imp-then-Reg 5\", \"Joint Imp-then-Reg\", \"Adaptive LR\"]\n",
    "    aux = filter(t -> startswith(t[:method], method), res)\n",
    "    # @show size(aux)\n",
    "    idcols = [:dataset, :SNR, :k, :kMissing, :splitnum]\n",
    "    gd = groupby(aux, idcols)\n",
    "\n",
    "    aux = similar(aux, 0)\n",
    "    for subdf in gd \n",
    "        scoremax = argmax(subdf[:,:score])\n",
    "        push!(aux, subdf[scoremax,names(aux)])\n",
    "    end\n",
    "    aux[!,:method] .= method*\" - best\"\n",
    "\n",
    "    res = vcat(res, aux)\n",
    "end\n",
    "\n",
    "CSV.write(\"realy/\"*\"FINAL_results.csv\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Synthetic-Data Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = \"synthetic/\"\n",
    "# for y_model in [\"linear\", \"tree\", \"nn\"]\n",
    "for y_model in [\"linear\", \"nn\"]\n",
    "    for m_model = [\"mar\", \"censoring\"]\n",
    "        dir = y_model*\"_\"*m_model*\"/\"\n",
    "        directory = setting*dir\n",
    "        \n",
    "        filelist = [f for f in readdir(directory*\"final/\") if endswith(f, \".csv\") && f ∉ [\"all_results.csv\",\"all_results_new.csv\"]]\n",
    "        res = similar(CSV.read(directory*\"final/\"*filelist[1], DataFrame),0)\n",
    "\n",
    "        for subdir = [\"final/\", \"rf_mia/\"]\n",
    "            filelist = [f for f in readdir(directory*subdir) if endswith(f, \".csv\") && f ∉ [\"all_results.csv\",\"all_results_new.csv\"]]\n",
    "    #         res = similar(CSV.read(directory*subdir*filelist[1], DataFrame),0)\n",
    "            for i in 1:length(filelist)\n",
    "                aux = CSV.read(directory*subdir*filelist[i], DataFrame)\n",
    "                if any(aux[:,:pMissing] .> 0)\n",
    "                    missingproba = unique(aux[aux[:,:pMissing] .> 0,:pMissing])[1]\n",
    "                    aux[!,:pMissing] .= missingproba\n",
    "                end\n",
    "                try\n",
    "                    res = vcat(res, aux)\n",
    "                catch \n",
    "                    println(\"Error with \", directory*subdir*filelist[i])\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        # filter!(t -> t[:k] > 0, res) #Remove dataset with only a bias term\n",
    "        res[!,:method_cat] = map(method_category, res[:,:method])\n",
    "        res[!,:X_setting] .= \"syn_X_\"*m_model\n",
    "        res[!,:Y_setting] .= \"syn_Y_\"*y_model\n",
    "\n",
    "        CSV.write(directory*\"FINAL_results.csv\", res)   \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = \"synthetic/\"\n",
    "# for y_model in [\"linear\", \"tree\", \"nn\"]\n",
    "for y_model in [\"linear\", \"nn\"]\n",
    "    for m_model = [\"mar\", \"censoring\"]\n",
    "        dir = y_model*\"_\"*m_model*\"/\"\n",
    "        directory = setting*dir\n",
    "        \n",
    "        filelist = [f for f in readdir(directory*\"final/\") if endswith(f, \".csv\") && f ∉ [\"all_results.csv\",\"all_results_new.csv\"]]\n",
    "        res = similar(CSV.read(directory*\"final/\"*filelist[1], DataFrame),0)\n",
    "\n",
    "        for subdir = [\"high_n/\"]\n",
    "            filelist = [f for f in readdir(directory*subdir) if endswith(f, \".csv\") && f ∉ [\"all_results.csv\",\"all_results_new.csv\"]]\n",
    "    #         res = similar(CSV.read(directory*subdir*filelist[1], DataFrame),0)\n",
    "            for i in 1:length(filelist)\n",
    "                aux = CSV.read(directory*subdir*filelist[i], DataFrame)\n",
    "                if any(aux[:,:pMissing] .> 0)\n",
    "                    missingproba = unique(aux[aux[:,:pMissing] .> 0,:pMissing])[1]\n",
    "                    aux[!,:pMissing] .= missingproba\n",
    "                end\n",
    "                try\n",
    "                    res = vcat(res, aux)\n",
    "                catch \n",
    "                    println(\"Error with \", directory*subdir*filelist[i])\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        # filter!(t -> t[:k] > 0, res) #Remove dataset with only a bias term\n",
    "        res[!,:method_cat] = map(method_category, res[:,:method])\n",
    "        res[!,:X_setting] .= \"syn_X_\"*m_model\n",
    "        res[!,:Y_setting] .= \"syn_Y_\"*y_model\n",
    "\n",
    "        CSV.write(directory*\"HIGHN_results.csv\", res)   \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = CSV.read(\"synthetic/linear_mar/FINAL_results.csv\", DataFrame) \n",
    "df[!,:setting] .= \"1 - Lin-MAR\"\n",
    "\n",
    "aux = CSV.read(\"synthetic/linear_censoring/FINAL_results.csv\", DataFrame) \n",
    "aux[!,:setting] .= \"2 - Lin-NMAR\"\n",
    "df = vcat(df, aux)\n",
    " \n",
    "aux = CSV.read(\"synthetic/tree_mar/FINAL_results.csv\", DataFrame) \n",
    "aux[!,:setting] .= \"3 - Tree-MAR\"\n",
    "df = vcat(df, aux)\n",
    "\n",
    "aux = CSV.read(\"synthetic/tree_censoring/FINAL_results.csv\", DataFrame) \n",
    "aux[!,:setting] .= \"4 - Tree-NMAR\"\n",
    "df = vcat(df, aux)\n",
    "\n",
    "aux = CSV.read(\"synthetic/nn_mar/FINAL_results.csv\", DataFrame) \n",
    "aux[!,:setting] .= \"5 - NN-MAR\"\n",
    "df = vcat(df, aux)\n",
    "\n",
    "aux = CSV.read(\"synthetic/nn_censoring/FINAL_results.csv\", DataFrame) \n",
    "aux[!,:setting] .= \"6 - NN-NMAR\"\n",
    "df = vcat(df, aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combine(groupby(df, [:dataset, :method, :setting]), nrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique(combine(groupby(df, [:dataset, :method, :setting]), nrow)[:,:nrow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter( t-> t[:nrow] < 90, combine(groupby(res, [:dataset, :method, :setting]), nrow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pbdata = unique(filter( t -> t[:nrow] < 90, combine(groupby(df, [:dataset, :method, :setting]), nrow))[:,[:method, :setting, :dataset]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aux = filter( t -> t[:dataset] ∈ pbdata && t[:nrow] < 10, combine(groupby(df, [:dataset, :method, :setting, :pMissing]), nrow))\n",
    "unique(aux[:,[:dataset, :setting, :pMissing, :nrow]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter(t -> t[:pMissing] == 0.1, unique(aux[:,[:dataset, :setting, :pMissing, :nrow]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter(t -> t[:pMissing] == 0.3, unique(aux[:,[:dataset, :setting, :pMissing, :nrow]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter(t -> startswith(t[:setting], \"5\"), unique(aux[:,[:dataset, :setting, :pMissing, :nrow]]))"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
